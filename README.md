# SPIFFE/SPIRE Fresh Mac Laptop Development Environment

**üçé Fresh Mac Install ‚Üí üî¨ Local Testing ‚Üí üè¢ Enterprise Deployment**

This project provides a **complete fresh Mac laptop SPIFFE/SPIRE installation experience** that simulates getting a brand new MacBook and setting up enterprise-grade identity management. The idempotent setup tears down any existing environment and rebuilds from scratch, ensuring consistent developer experience across teams.

## Architecture

### üíª Local Testing Environment
The setup consists of two minikube clusters simulating enterprise multi-cluster topology:

1. **SPIRE Server Cluster** (`spire-server-cluster`): Identity control plane
   - SPIRE Server for SPIFFE ID management
   - PostgreSQL database for registration entries
   - Trust bundle management

2. **Workload Cluster** (`workload-cluster`): Application workload environment  
   - SPIRE Agent for workload attestation
   - Enterprise service examples (user-service, payment-api, inventory-service)
   - Real-time monitoring dashboard

### üè¢ Enterprise Deployment Path
*In production environments*, this architecture scales to:
- Multiple geographic regions with dedicated SPIRE servers
- Separate clusters for different security zones (DMZ, internal, data)
- High-availability PostgreSQL with backup/recovery
- Enterprise-grade monitoring and alerting

## Components

- **SPIRE Server**: Manages SPIFFE IDs and issues SVIDs (SPIFFE Verifiable Identity Documents)
- **PostgreSQL Database**: Stores SPIRE registration entries and other data
- **SPIRE Agent**: Runs on the workload cluster and attests workloads
- **Example Workload Services**: Three different services that obtain SPIFFE IDs from the SPIRE agent

## üóÑÔ∏è PostgreSQL Storage Considerations

### üíª **Local Development Storage**
**Current Allocation**: 5GB (optimal for laptop testing and development)

**Local Development Guidelines**:
- **Minimum**: 2GB (basic testing with limited registrations)
- **Recommended**: 5GB (extensive testing scenarios with growth buffer)
- **Maximum**: 10GB (for complex multi-workload development)
- **Storage Class**: `standard` (minikube default, sufficient for development)

### üè¢ **Enterprise Production Storage**

#### **Capacity Planning by Scale**

| Deployment Size | Registration Entries | Database Size | Recommended Storage | Buffer |
|-----------------|---------------------|---------------|-------------------|---------|
| **Small** (100-500 workloads) | 1K-5K entries | ~10-50MB | **20GB** | 400x |
| **Medium** (500-2K workloads) | 5K-20K entries | ~50-200MB | **100GB** | 500x |
| **Large** (2K-10K workloads) | 20K-100K entries | ~200MB-1GB | **500GB** | 500x |
| **Enterprise** (10K+ workloads) | 100K+ entries | ~1-5GB | **2TB+** | 400x |

#### **Storage Requirements Breakdown**

**Base PostgreSQL Installation**: ~200-500MB
- PostgreSQL binaries and system databases
- Initial configuration and metadata
- Transaction logs and temporary files

**SPIRE Registration Data**: ~10KB per entry average
- **Registration Entries**: ~2-5KB per workload identity
- **Agent Attestations**: ~1-3KB per agent node
- **Trust Bundle Data**: ~1-5KB per trust domain
- **Join Tokens**: ~1KB per token (temporary)
- **Certificate Storage**: ~2-4KB per active certificate

**PostgreSQL Overhead**: 20-30% of data size
- Indexes and metadata (~15% of table data)
- WAL (Write-Ahead Logging) files (~10-15% during high activity)
- Temporary query processing space (~5-10%)

#### **High Availability Storage**

**Primary Database**:
- **Data Volume**: Base calculation + 100% buffer
- **WAL Volume**: 25% of data volume (separate disk recommended)
- **Backup Volume**: 200% of data volume (for point-in-time recovery)

**Read Replicas** (2-3 replicas recommended):
- **Storage per Replica**: Same as primary data volume
- **Network Storage**: For cross-region replication

#### **Performance Storage Classes**

**Local Development**:
- **Storage Class**: `standard` (minikube)
- **IOPS**: Not critical for development

**Production Recommendations**:
- **Storage Class**: `fast-ssd` or `gp3` (AWS), `pd-ssd` (GCP)
- **IOPS**: 3000+ for small deployments, 10K+ for enterprise
- **Throughput**: 250MB/s minimum, 500MB/s+ for large scale

#### **Growth Buffer Recommendations**

**Conservative Growth** (1-year planning):
- **Registration Growth**: 200-300% year-over-year
- **Storage Buffer**: 400-500% of current usage
- **Monitoring Threshold**: Alert at 60% capacity

**Aggressive Growth** (startup/rapid expansion):
- **Registration Growth**: 500-1000% year-over-year  
- **Storage Buffer**: 800-1000% of current usage
- **Auto-scaling**: Enable storage auto-expansion

#### **Backup and Recovery Storage**

**Backup Requirements**:
- **Full Backups**: Weekly (100% of database size)
- **Incremental Backups**: Daily (10-20% of database size)
- **Point-in-Time Recovery**: 30-day retention minimum
- **Total Backup Storage**: ~500% of database size

**Disaster Recovery**:
- **Cross-Region Storage**: 200% of primary database
- **Backup Verification**: Monthly restore testing
- **RTO Target**: <4 hours for enterprise deployments

#### **Cost Optimization Strategies**

**Development/Staging**:
- Use `standard` storage classes for non-critical environments
- Implement automated cleanup of old test data
- Schedule backup retention cleanup (7-day retention)

**Production**:
- Tier older backups to cheaper storage (AWS S3 IA, Glacier)
- Implement data lifecycle policies for registration entries
- Monitor and right-size storage based on actual usage patterns

### üìä **Monitoring and Alerting**

**Critical Metrics**:
- **Storage Usage**: Alert at 70% capacity
- **IOPS Utilization**: Alert at 80% of provisioned IOPS  
- **Connection Pool**: Monitor PostgreSQL connection limits
- **WAL Size**: Monitor write-ahead log growth patterns

**Recommended Tools**:
- **Prometheus + Grafana**: For comprehensive monitoring
- **postgres_exporter**: PostgreSQL-specific metrics
- **Cloud Native**: AWS CloudWatch, GCP Monitoring, Azure Monitor

## üçé Fresh Mac Laptop Setup

### **üöÄ One-Command Fresh Install**
```bash
# Complete fresh Mac laptop SPIRE installation
./scripts/fresh-install.sh
```

This **idempotent script** simulates a fresh MacBook setup by:
- üßπ **Completely tearing down** any existing SPIRE environment
- üîÑ **Cleaning all local configurations** (Docker, minikube, kubectl contexts)
- üöÄ **Setting up fresh clusters** from scratch 
- ‚úÖ **Validating the installation** with real-time dashboard

#### ‚è±Ô∏è **Fresh Install Performance**
**Average Runtime: ~1.5-2 minutes** *(verified on MacBook with Docker)*

**Optimized Breakdown:**
- üóÇÔ∏è **Environment Teardown**: ~5 seconds
- üöÄ **Cluster Creation**: ~25-30 seconds (parallel minikube clusters)
- üì¶ **Kubernetes Deployments**: ~2-5 seconds  
- ‚è≥ **Pod Readiness**: ~45-60 seconds (SPIRE server, PostgreSQL, agents)
- ‚úÖ **Validation & Dashboard**: ~10-15 seconds

**Performance Notes:**
- **First-time runs**: May take 3-4 minutes due to Docker image downloads
- **Cached runs**: Typically complete in 1-2 minutes with downloaded images
- **Parallel optimization**: Clusters start simultaneously for faster setup
- **SSD storage**: Recommended for optimal performance
- **8GB+ RAM**: Required for smooth multi-cluster operation

**Verified Timing Results:**
- Component test: 2.4 minutes | Quick test: 1.0 minutes | Realistic test: 1.2 minutes
- **Average: 1.5 minutes** for environments with cached Docker images

### Prerequisites for macOS Development
**Install via Homebrew** (as you would on a fresh Mac):
```bash
brew install minikube kubectl node jq
```

### Manual Setup (Alternative)
If you prefer step-by-step control:

1. **Clone and Setup**:
   ```bash
   git clone <repository-url>
   cd spire-dev
   ```

2. **Run individual setup scripts**:
   ```bash
   chmod +x scripts/setup-clusters.sh scripts/verify-setup.sh
   ./scripts/setup-clusters.sh
   ./scripts/verify-setup.sh
   ```

### üîÑ Reset to Fresh State Anytime
```bash
# Return to fresh Mac laptop state
./scripts/fresh-install.sh
```

### üõ†Ô∏è Troubleshooting
**Having issues?** The fresh install script solves 90% of problems:
```bash
./scripts/fresh-install.sh  # ‚Üê Try this first!
```

For detailed troubleshooting: **[docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)**

**üìÅ Project Structure:** See **[docs/PROJECT_STRUCTURE.md](docs/PROJECT_STRUCTURE.md)** for complete repository organization

## üè¢ Enterprise Deployment Considerations

### Adapting for Production Kubernetes
While this project excels at local laptop testing, **enterprise deployment** requires these key adaptations:

**Security Hardening:**
- Replace minikube with production Kubernetes clusters (EKS, GKE, AKS)
- Implement proper RBAC with service accounts and role bindings
- Use secrets management (Vault, AWS Secrets Manager) instead of plain ConfigMaps
- Enable TLS encryption for all SPIRE server communications

**High Availability:**
- Deploy SPIRE server with multiple replicas and load balancing
- Configure PostgreSQL with primary/replica setup and automated failover
- Implement cross-region trust bundle distribution
- Set up cluster auto-scaling and resource limits

**Operations & Monitoring:**
- Integrate with enterprise logging (Splunk, ELK stack)
- Set up Prometheus metrics collection and Grafana dashboards
- Configure alerting for SPIRE server downtime and certificate expiration
- Implement backup/restore procedures for registration entries

**See [docs/HELM_DEPLOYMENT_GUIDE.md](docs/HELM_DEPLOYMENT_GUIDE.md) for production deployment using Helm charts.**

## üíº Workload Services

The setup includes three example enterprise workload services:

1. **user-service**: A user management API service with SPIFFE ID `spiffe://example.org/workload/user-service`
2. **payment-api**: A payment processing API service with SPIFFE ID `spiffe://example.org/workload/payment-api`
3. **inventory-service**: An inventory management API service with SPIFFE ID `spiffe://example.org/workload/inventory-service`

Each service is configured to access the SPIRE agent socket and can obtain its SPIFFE ID using the Workload API.

## üìä Real-Time Monitoring Dashboard

### üíª Local Development Dashboard
Perfect for **fresh Mac laptop testing** with live data from your minikube clusters:

```bash
# Ensure fresh environment first
./scripts/fresh-install.sh

# Start real-time dashboard server
./web/start-dashboard.sh

# Open dashboard in browser (macOS)
open http://localhost:3000/web-dashboard.html
```

The **Node.js web server** provides real-time API integration and professional development experience.

The dashboard provides **real-time pod data** from both clusters, replacing mock data with actual kubectl information. Ideal for:
- Testing identity propagation across services
- Debugging SPIRE agent connectivity issues  
- Monitoring certificate expiration during development
- Validating configuration changes instantly

### üè¢ Enterprise Dashboard Extensions
*For production environments*, extend this dashboard with:
- Integration with enterprise monitoring (Datadog, New Relic)
- SAML/OAuth authentication for team access
- Multi-region cluster aggregation
- Automated alerting and escalation workflows

#### Dashboard Tabs

- **Overview Tab**: Real-time cluster status with clickable component health cards and SPIRE metrics summary
- **SPIRE Server Tab**: Detailed server component status and pod monitoring
- **Database Tab**: PostgreSQL database monitoring with storage and connection metrics and interactive policy viewer
- **Agents Tab**: SPIRE agent health tracking across all nodes
- **Workloads Tab**: Service deployment status with detailed workload metrics
- **SPIRE Metrics Tab**: ‚≠ê **Advanced telemetry with interactive drilldown capabilities**
- **Commands Tab**: Comprehensive kubectl commands for troubleshooting and metrics collection

#### üìä **Enhanced Overview Tab**

The Overview tab now provides comprehensive system monitoring with interactive component tiles:

##### **Interactive Component Cards**
- **SPIRE Server** - Server cluster status with click-through to detailed monitoring
- **PostgreSQL DB** - Database health and storage status with policy access
- **SPIRE Agents** - Active agent count with health overview
- **Workload Services** - Running service count and status summary  
- **SPIRE Metrics** ‚≠ê **NEW** - Real-time activity monitoring with dynamic status indicators:
  - üü¢ **High Activity** - Active system with substantial RPC calls and agent connections
  - üü° **Moderate Activity** - Normal operational load with regular traffic
  - üîµ **Low Activity** - Minimal system activity detected
  - üìä **Default State** - Interactive telemetry ready for detailed analysis

Each card provides:
- **Visual Status Indicators** - Color-coded health and activity levels
- **Quick Metrics** - Key performance indicators at a glance  
- **Direct Navigation** - One-click access to detailed monitoring tabs
- **Real-time Updates** - Automatic refresh with configurable intervals

#### üîç Interactive SPIRE Metrics & Telemetry

The enhanced dashboard now includes industry-standard SPIFFE/SPIRE observability metrics with interactive drilldown capabilities:

##### Clickable Metric Tiles
Each metric tile is interactive and opens detailed analysis modals:

1. **Server RPC Calls** üìä
   - **Summary**: Total RPC operations across all SPIRE server endpoints
   - **Drilldown Details**:
     - Real-time RPC call volumes and response times
     - Success rates and error analysis
     - Breakdown by RPC method (attest_agent, fetch_x509_svid, fetch_jwt_svid, etc.)
     - Performance trends and peak operation analysis
     - Recent activity timeline with timing details

2. **Agent Connections** üîó
   - **Summary**: Active SPIRE agent connections and health status
   - **Drilldown Details**:
     - Connection pool usage and session duration analysis
     - Failed connection tracking and retry patterns
     - Individual agent status with node mapping
     - Heartbeat monitoring and data transfer metrics
     - Connection timeline and health trends

3. **SVID Issuance Rate** üé´
   - **Summary**: Real-time SVID (SPIFFE Verifiable Identity Document) issuance metrics
   - **Drilldown Details**:
     - Current issuance rates and daily volume analysis
     - X.509 vs JWT SVID distribution breakdown
     - Issuance performance metrics and timing analysis
     - Common selectors and workload patterns
     - Recent issuance activity with SPIFFE ID details

4. **Certificate Expiry** ‚è∞
   - **Summary**: Certificate lifecycle monitoring and expiry warnings
   - **Drilldown Details**:
     - Immediate expiry alerts (< 24 hours)
     - Weekly expiry forecasting and planning
     - Auto-renewal success rates and failure analysis
     - CA certificate validity and rotation tracking
     - Detailed expiry timeline and renewal history

##### Advanced Metrics Tables
- **SPIRE Server Metrics**: Comprehensive tracking of server-side operations
- **SPIRE Agent Metrics**: Agent-specific performance and health indicators
- **Alert Thresholds**: Production-ready monitoring with severity levels
- **Telemetry Configuration**: Prometheus endpoints and collection settings

##### Interactive Features
- **Hover Effects**: Visual indicators showing clickable elements with magnifying glass icons
- **Modal Dialogs**: Detailed metric analysis with smooth fade-in animations
- **Trend Analysis**: Visual trend indicators (‚Üó up, ‚Üò down, ‚Üí stable, ‚ö† warning)
- **Keyboard Navigation**: ESC key support for closing modals
- **Responsive Design**: Mobile-friendly layout with touch support

#### Accessing the Web Dashboard

After running the setup, start the dashboard server and access via localhost:

```bash
# Start the dashboard server
./web/start-dashboard.sh

# Open in browser
open http://localhost:3000/web-dashboard.html
```

The dashboard server provides:
- **Real-time API endpoint**: `http://localhost:3000/api/pod-data`
- **Web interface**: `http://localhost:3000/web-dashboard.html`
- **Live pod data** directly from your minikube clusters

#### Production-Ready Features
- **Real-time Data**: Auto-refresh capabilities with configurable intervals (5s-60s)
- **Prometheus Integration**: Ready for production metrics collection (port 9988)
- **Alert Management**: Industry-standard thresholds for operational monitoring
- **Performance Monitoring**: Response time tracking and error rate analysis
- **Security Compliance**: Certificate lifecycle and expiry management
- **Operational Insights**: Historical trends and capacity planning data

#### Dashboard Capabilities
- **Responsive Design**: Optimized for desktop and mobile browsers with adaptive grid layouts
- **Live Updates**: Real-time status with color-coded health indicators and activity monitoring
- **Tabbed Interface**: Organized monitoring sections with smooth transitions and cross-tab navigation
- **Interactive Elements**: Clickable tiles, detailed drilldown modals, and database policy viewers
- **Enhanced Overview**: Five-tile dashboard with dynamic SPIRE metrics integration
- **Command Integration**: Built-in kubectl and metrics collection commands with database queries
- **Export Ready**: Structured for integration with monitoring platforms and enterprise systems


## Useful Commands

### üìÅ **SPIFFE Namespace Structure (Best Practices)**

Following official SPIFFE documentation recommendations:

- **`spire-server`** - SPIRE Server, PostgreSQL database, control plane
- **`spire-system`** - SPIRE Agents and system components  
- **`production`** - Enterprise workload services

### Check SPIRE Server Status
```bash
kubectl --context spire-server-cluster -n spire-server get pods
```

### Check SPIRE Agent Status
```bash
kubectl --context workload-cluster -n spire-system get pods
```

### Check Workload Services
```bash
kubectl --context workload-cluster -n production get pods
```

### List SPIRE Registration Entries
```bash
SERVER_POD=$(kubectl --context spire-server-cluster -n spire-server get pod -l app=spire-server -o jsonpath='{.items[0].metadata.name}')
kubectl --context spire-server-cluster -n spire-server exec $SERVER_POD -- /opt/spire/bin/spire-server entry show
```

### üè∑Ô∏è **SPIFFE ID Patterns (Istio Compatible)**

The setup uses standard SPIFFE ID patterns for enterprise integration:

```
# SPIRE Agent
spiffe://example.org/agent/k8s_psat/cluster/spire-agent

# Workload Services (Istio pattern)
spiffe://example.org/ns/production/sa/user-service
spiffe://example.org/ns/production/sa/payment-api
spiffe://example.org/ns/production/sa/inventory-service
```

### SPIRE Metrics and Telemetry Commands

#### Access SPIRE Server Metrics (Prometheus Format)
```bash
# Port-forward to access metrics endpoint
kubectl --context spire-server-cluster -n spire-server port-forward spire-server-0 9988:9988 &

# Fetch metrics
curl http://localhost:9988/metrics
```

#### Access SPIRE Agent Metrics
```bash
# Get agent pod name
AGENT_POD=$(kubectl --context workload-cluster -n spire-system get pod -l app=spire-agent -o jsonpath='{.items[0].metadata.name}')

# Port-forward to agent metrics
kubectl --context workload-cluster -n spire-system port-forward $AGENT_POD 9988:9988 &

# Fetch agent metrics
curl http://localhost:9988/metrics
```

#### View SPIRE Server Telemetry Configuration
```bash
kubectl --context spire-server-cluster -n spire-server get configmap spire-server-config -o yaml | grep -A 20 telemetry
```

#### Monitor Real-time SPIRE Operations
```bash
# Watch SPIRE server logs
kubectl --context spire-server-cluster -n spire-server logs -f spire-server-0

# Watch agent logs
kubectl --context workload-cluster -n spire-system logs -f -l app=spire-agent

# Monitor certificate operations
kubectl --context spire-server-cluster -n spire-server logs spire-server-0 | grep -i "certificate\|svid\|attest"
```

### Push Git Changes
```
./scripts/push-changes.sh
```
This script will:
- Check for uncommitted changes
- Verify if there are commits to push
- Push the changes to the remote repository

## Cleanup

To delete the minikube clusters:
```
minikube delete -p spire-server-cluster
minikube delete -p workload-cluster
```

## Project Structure

```
.
‚îú‚îÄ‚îÄ k8s/                           # Kubernetes manifests
‚îÇ   ‚îú‚îÄ‚îÄ spire-db/                  # Database components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres-deployment.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ postgres-pvc.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ postgres-service.yaml
‚îÇ   ‚îú‚îÄ‚îÄ spire-server/              # SPIRE server components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ registration-entries.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server-configmap.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server-rbac.yaml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server-service.yaml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ server-statefulset.yaml
‚îÇ   ‚îî‚îÄ‚îÄ workload-cluster/          # Workload cluster components
‚îÇ       ‚îú‚îÄ‚îÄ agent-configmap.yaml
‚îÇ       ‚îú‚îÄ‚îÄ agent-daemonset.yaml
‚îÇ       ‚îú‚îÄ‚îÄ agent-rbac.yaml
‚îÇ       ‚îú‚îÄ‚îÄ namespace.yaml
‚îÇ       ‚îú‚îÄ‚îÄ user-service-deployment.yaml
‚îÇ       ‚îú‚îÄ‚îÄ payment-api-deployment.yaml
‚îÇ       ‚îî‚îÄ‚îÄ inventory-service-deployment.yaml
‚îú‚îÄ‚îÄ scripts/                       # Setup and utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ setup-clusters.sh          # Main setup script
‚îÇ   ‚îú‚îÄ‚îÄ verify-setup.sh           # Verification script
‚îÇ   ‚îî‚îÄ‚îÄ push-changes.sh           # Git push script
‚îú‚îÄ‚îÄ web/                          # Web dashboard
‚îÇ   ‚îú‚îÄ‚îÄ web-dashboard.html        # Main dashboard interface
‚îÇ   ‚îú‚îÄ‚îÄ server.js                 # Node.js server
‚îÇ   ‚îî‚îÄ‚îÄ start-dashboard.sh        # Startup script
‚îî‚îÄ‚îÄ README.md                     # This file
```

## Technical Architecture

### SPIRE Metrics & Telemetry Implementation

The enhanced dashboard implements industry-standard SPIFFE/SPIRE observability following the official telemetry specifications:

#### Metrics Collection Architecture
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   SPIRE Server  ‚îÇ    ‚îÇ   SPIRE Agent   ‚îÇ    ‚îÇ  Web Dashboard  ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ Port 9988       ‚îÇ    ‚îÇ Port 9988       ‚îÇ    ‚îÇ Interactive UI  ‚îÇ
‚îÇ /metrics        ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ /metrics        ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ Drilldown       ‚îÇ
‚îÇ (Prometheus)    ‚îÇ    ‚îÇ (Prometheus)    ‚îÇ    ‚îÇ Modals          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ                       ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Prometheus    ‚îÇ
                    ‚îÇ   (Optional)    ‚îÇ
                    ‚îÇ   Production    ‚îÇ
                    ‚îÇ   Integration   ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Key Metrics Categories

1. **SPIRE Server Metrics**
   - `spire_server.rpc.*` - RPC operation counters and timing
   - `spire_server.ca.*` - Certificate authority operations
   - `spire_server.datastore.*` - Database operation metrics

2. **SPIRE Agent Metrics**
   - `spire_agent.cache_manager.*` - SVID cache performance
   - `spire_agent.sds_api.*` - Service Discovery Service metrics
   - `spire_agent.sync_manager.*` - Entry synchronization tracking

3. **Operational Metrics**
   - Connection health and session management
   - Certificate lifecycle and expiry monitoring
   - Performance trends and capacity planning

#### Dashboard Technology Stack
- **Frontend**: Modern HTML5/CSS3/JavaScript
- **UI Framework**: CSS Grid and Flexbox for responsive design
- **Animations**: CSS3 transitions and keyframe animations
- **Data Handling**: Asynchronous JavaScript with Promise-based architecture
- **Modal System**: Custom modal implementation with keyboard navigation
- **Real-time Updates**: Configurable auto-refresh with background data fetching

#### Production Integration
- **Prometheus Compatible**: Standard `/metrics` endpoints on port 9988
- **Grafana Ready**: Metrics structured for dashboard import
- **Alert Manager**: Pre-configured thresholds for operational alerts
- **Kubernetes Native**: Integrated with kubectl and cluster operations
```

## üéØ **Production Helm Charts Template**

This repository includes **production-ready Helm charts** that serve as a comprehensive template for implementing SPIRE in production Kubernetes environments. The charts replace manual Kubernetes manifests with a templated, configurable, and maintainable solution.

### üì¶ **Helm Chart Architecture**

```
helm-charts/spire/
‚îú‚îÄ‚îÄ Chart.yaml                    # Chart metadata with PostgreSQL dependency
‚îú‚îÄ‚îÄ values.yaml                   # Default configuration values
‚îú‚îÄ‚îÄ values/
‚îÇ   ‚îú‚îÄ‚îÄ development.yaml          # Development environment overrides
‚îÇ   ‚îî‚îÄ‚îÄ production.yaml           # Production environment overrides
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îú‚îÄ‚îÄ _helpers.tpl              # Template functions and helpers
‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml            # Namespace management
‚îÇ   ‚îú‚îÄ‚îÄ server-*.yaml             # SPIRE Server components
‚îÇ   ‚îú‚îÄ‚îÄ agent-*.yaml              # SPIRE Agent components
‚îÇ   ‚îî‚îÄ‚îÄ workload-*.yaml           # Example workload services
‚îî‚îÄ‚îÄ README.md                     # Detailed chart documentation
```

### üöÄ **Key Advantages Over Manual Manifests**

| Feature | Manual K8s Manifests | Helm Charts Template |
|---------|----------------------|----------------------|
| **Deployment** | Multiple `kubectl apply` commands | Single `helm install` command |
| **Environment Management** | Separate manifest sets per environment | Single chart + environment values |
| **Configuration** | Hard-coded values in YAML | Templated with environment variables |
| **Updates** | Manual file editing and reapplication | `helm upgrade` with value overrides |
| **Rollbacks** | Manual backup and restore | `helm rollback` to previous version |
| **Dependencies** | Manual PostgreSQL setup | Automatic dependency management |
| **Validation** | No built-in validation | Template validation and dry-run |
| **Versioning** | Git-based file tracking | Helm release versioning |

### üè≠ **Production Implementation Guide**

#### **1. Template Customization for Your Environment**

**Step 1: Clone and Customize Values**
```bash
# Copy the chart template to your infrastructure repository
cp -r helm-charts/spire /path/to/your/infrastructure/charts/

# Create organization-specific values
cat > /path/to/your/infrastructure/charts/spire/values/company-production.yaml <<EOF
global:
  trustDomain: "company.internal"
  clusterName: "prod-k8s-cluster"
  imageRegistry: "your-registry.company.com"

spireServer:
  replicaCount: 3  # High availability
  image:
    repository: "spiffe/spire-server"
    tag: "1.6.3"
  
  resources:
    requests:
      cpu: 1000m
      memory: 1Gi
    limits:
      cpu: 2000m
      memory: 2Gi
  
  persistence:
    size: 20Gi
    storageClass: "fast-ssd"
  
  config:
    logLevel: "WARN"

postgresql:
  auth:
    existingSecret: "postgresql-credentials"
  primary:
    persistence:
      size: 100Gi
      storageClass: "fast-ssd"
    resources:
      requests:
        cpu: 2000m
        memory: 4Gi
      limits:
        cpu: 4000m
        memory: 8Gi

# Production security settings
security:
  podSecurityStandards:
    enabled: true
    enforce: "restricted"

# Enable monitoring
monitoring:
  prometheus:
    enabled: true
    serviceMonitor:
      enabled: true
EOF
```

**Step 2: Customize Registration Entries**
```yaml
# Add your organization's SPIFFE ID structure
registrationEntries:
  enabled: true
  entries:
    # Node attestation entry
    - spiffeId: "spiffe://company.internal/spire/agent/k8s_psat/prod-cluster"
      parentId: "spiffe://company.internal/spire/server"
      selectors:
        - "k8s_psat:cluster:prod-cluster"
      ttl: 3600
    
    # Enterprise application entries
    - spiffeId: "spiffe://company.internal/workload/user-service"
      parentId: "spiffe://company.internal/spire/agent/k8s_psat/prod-cluster"
      selectors:
        - "k8s:ns:production"
        - "k8s:sa:user-service"
        - "k8s:pod-label:app:user-service"
        - "k8s:pod-label:service:user-management"
      ttl: 1200  # 20 minutes for user management
    
    - spiffeId: "spiffe://company.internal/workload/payment-api"
      parentId: "spiffe://company.internal/spire/agent/k8s_psat/prod-cluster"
      selectors:
        - "k8s:ns:production"
        - "k8s:sa:payment-api"
        - "k8s:pod-label:app:payment-api"
        - "k8s:pod-label:service:payment-processing"
      ttl: 600  # 10 minutes for payment security
    
    - spiffeId: "spiffe://company.internal/workload/inventory-service"
      parentId: "spiffe://company.internal/spire/agent/k8s_psat/prod-cluster"
      selectors:
        - "k8s:ns:production"
        - "k8s:sa:inventory-service"
        - "k8s:pod-label:app:inventory-service"
        - "k8s:pod-label:service:inventory-management"
      ttl: 1800  # 30 minutes for inventory operations
```

#### **2. Multi-Environment Deployment Strategy**

**Environment Structure:**
```bash
# Recommended directory structure
infrastructure/
‚îú‚îÄ‚îÄ charts/
‚îÇ   ‚îî‚îÄ‚îÄ spire/                    # Customized chart from this template
‚îî‚îÄ‚îÄ environments/
    ‚îú‚îÄ‚îÄ development/
    ‚îÇ   ‚îú‚îÄ‚îÄ values.yaml          # Dev-specific values
    ‚îÇ   ‚îî‚îÄ‚îÄ secrets.yaml         # Dev secrets (encrypted)
    ‚îú‚îÄ‚îÄ staging/
    ‚îÇ   ‚îú‚îÄ‚îÄ values.yaml          # Staging-specific values
    ‚îÇ   ‚îî‚îÄ‚îÄ secrets.yaml         # Staging secrets (encrypted)
    ‚îî‚îÄ‚îÄ production/
        ‚îú‚îÄ‚îÄ values.yaml          # Production-specific values
        ‚îî‚îÄ‚îÄ secrets.yaml         # Production secrets (encrypted)
```

**Deployment Automation:**
```bash
#!/bin/bash
# deploy-spire.sh - Production deployment script

ENVIRONMENT=${1:-production}
CHART_PATH="./charts/spire"
VALUES_PATH="./environments/$ENVIRONMENT"

echo "üöÄ Deploying SPIRE to $ENVIRONMENT environment..."

# Validate configuration
helm lint $CHART_PATH --values $VALUES_PATH/values.yaml
if [ $? -ne 0 ]; then
    echo "‚ùå Chart validation failed"
    exit 1
fi

# Deploy with production settings
helm upgrade --install spire-$ENVIRONMENT $CHART_PATH \
  --namespace spire-$ENVIRONMENT \
  --create-namespace \
  --values $VALUES_PATH/values.yaml \
  --wait \
  --timeout 15m \
  --atomic  # Rollback on failure

# Verify deployment
if helm status spire-$ENVIRONMENT -n spire-$ENVIRONMENT; then
    echo "‚úÖ SPIRE deployment successful"
    
    # Run post-deployment tests
    helm test spire-$ENVIRONMENT -n spire-$ENVIRONMENT
    
    # Verify SPIRE server health
    kubectl exec -n spire-$ENVIRONMENT deployment/spire-$ENVIRONMENT-server -- \
      /opt/spire/bin/spire-server healthcheck
else
    echo "‚ùå SPIRE deployment failed"
    exit 1
fi
```

#### **3. Security Hardening for Production**

**Network Security:**
```yaml
# values/security-hardened.yaml
networking:
  networkPolicies:
    enabled: true
    
  # Restrict ingress to SPIRE server
  ingress:
    spireServer:
      - from:
        - namespaceSelector:
            matchLabels:
              name: spire-production
        ports:
        - protocol: TCP
          port: 8081
      - from:
        - namespaceSelector:
            matchLabels:
              name: monitoring
        ports:
        - protocol: TCP
          port: 9988  # Metrics port

# Pod security contexts
spireServer:
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 1000
    capabilities:
      drop:
        - ALL

spireAgent:
  securityContext:
    allowPrivilegeEscalation: false
    readOnlyRootFilesystem: true
    runAsNonRoot: true
    runAsUser: 1000
    capabilities:
      drop:
        - ALL
      add:
        - NET_ADMIN  # Required for agent operations
```

**Secret Management:**
```bash
# Create production secrets
kubectl create secret generic postgresql-credentials \
  --from-literal=postgres-password="$(openssl rand -base64 32)" \
  --namespace spire-production

kubectl create secret generic spire-server-ca \
  --from-file=ca.crt=/path/to/your/ca.crt \
  --from-file=ca.key=/path/to/your/ca.key \
  --namespace spire-production
```

#### **4. High Availability Configuration**

**Multi-Zone Deployment:**
```yaml
# Production HA configuration
spireServer:
  replicaCount: 3
  
  # Anti-affinity for zone distribution
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchLabels:
            app.kubernetes.io/component: spire-server
        topologyKey: topology.kubernetes.io/zone
    
    # Prefer different nodes
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: node-role.kubernetes.io/spire
            operator: In
            values:
            - "true"

# Database HA with read replicas
postgresql:
  architecture: replication
  readReplicas:
    replicaCount: 2
  primary:
    persistence:
      size: 100Gi
    resources:
      requests:
        cpu: 2000m
        memory: 4Gi
```

#### **5. Monitoring and Observability Integration**

**Prometheus Integration:**
```yaml
# Production monitoring configuration
monitoring:
  prometheus:
    enabled: true
    serviceMonitor:
      enabled: true
      interval: 30s
      scrapeTimeout: 10s
      labels:
        release: prometheus-operator
    
    # Custom alerting rules
    prometheusRule:
      enabled: true
      rules:
        - alert: SPIREServerDown
          expr: up{job="spire-server"} == 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "SPIRE Server instance is down"
            description: "SPIRE Server {{ $labels.instance }} has been down for more than 5 minutes"
        
        - alert: SPIREAgentDown
          expr: up{job="spire-agent"} == 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "SPIRE Agent instance is down"

  # Grafana dashboards
  grafana:
    enabled: true
    dashboards:
      spire:
        enabled: true
        datasource: prometheus
```

### üîÑ **Operational Procedures**

#### **Upgrade Strategy**

```bash
#!/bin/bash
# upgrade-spire.sh - Safe production upgrade procedure

ENVIRONMENT="production"
NAMESPACE="spire-$ENVIRONMENT"

echo "üîÑ Starting SPIRE upgrade process..."

# 1. Backup current state
echo "üì¶ Creating backup..."
helm get all spire-$ENVIRONMENT -n $NAMESPACE > "backup-$(date +%Y%m%d-%H%M%S).yaml"

# 2. Database backup
kubectl exec -n $NAMESPACE spire-$ENVIRONMENT-postgresql-0 -- \
  pg_dumpall -U postgres | gzip > "db-backup-$(date +%Y%m%d-%H%M%S).sql.gz"

# 3. Validate new configuration
echo "‚úÖ Validating new configuration..."
helm template spire ./charts/spire \
  --values ./environments/$ENVIRONMENT/values.yaml \
  --validate

# 4. Perform rolling upgrade
echo "üöÄ Performing rolling upgrade..."
helm upgrade spire-$ENVIRONMENT ./charts/spire \
  --namespace $NAMESPACE \
  --values ./environments/$ENVIRONMENT/values.yaml \
  --wait \
  --timeout 20m

# 5. Verify upgrade
echo "üîç Verifying upgrade..."
kubectl rollout status statefulset/spire-$ENVIRONMENT-server -n $NAMESPACE
kubectl rollout status daemonset/spire-$ENVIRONMENT-agent -n $NAMESPACE

# 6. Health check
kubectl exec -n $NAMESPACE deployment/spire-$ENVIRONMENT-server -- \
  /opt/spire/bin/spire-server healthcheck

echo "‚úÖ SPIRE upgrade completed successfully"
```

#### **Disaster Recovery**

```bash
#!/bin/bash
# disaster-recovery.sh - SPIRE disaster recovery procedure

BACKUP_DIR=$1
TARGET_ENVIRONMENT=${2:-production}

if [ -z "$BACKUP_DIR" ]; then
    echo "Usage: $0 <backup-directory> [environment]"
    exit 1
fi

echo "üö® Starting SPIRE disaster recovery..."

# 1. Deploy fresh SPIRE instance
helm install spire-$TARGET_ENVIRONMENT ./charts/spire \
  --namespace spire-$TARGET_ENVIRONMENT \
  --create-namespace \
  --values ./environments/$TARGET_ENVIRONMENT/values.yaml \
  --wait

# 2. Restore database
echo "üì• Restoring database..."
gunzip -c $BACKUP_DIR/db-backup-*.sql.gz | \
kubectl exec -n spire-$TARGET_ENVIRONMENT spire-$TARGET_ENVIRONMENT-postgresql-0 -i -- \
  psql -U postgres

# 3. Restart SPIRE server to reload data
kubectl rollout restart statefulset/spire-$TARGET_ENVIRONMENT-server -n spire-$TARGET_ENVIRONMENT

echo "‚úÖ Disaster recovery completed"
```

### üìä **Production Readiness Checklist**

Before deploying SPIRE using this template in production:

#### **Infrastructure Requirements**
- [ ] **Kubernetes cluster** version 1.20+ with RBAC enabled
- [ ] **Storage class** configured for persistent volumes (preferably SSD)
- [ ] **Load balancer** or ingress controller for external access
- [ ] **Monitoring stack** (Prometheus, Grafana) deployed
- [ ] **Backup solution** for persistent data

#### **Security Configuration**
- [ ] **Pod Security Standards** enforced (restricted level)
- [ ] **Network policies** configured for traffic isolation
- [ ] **Secrets management** using Kubernetes secrets or external systems
- [ ] **Image scanning** enabled for container vulnerabilities
- [ ] **RBAC policies** following principle of least privilege

#### **Operational Readiness**
- [ ] **Monitoring and alerting** configured for SPIRE components
- [ ] **Log aggregation** setup for centralized logging
- [ ] **Backup procedures** tested and documented
- [ ] **Disaster recovery** plan created and validated
- [ ] **Upgrade procedures** documented and tested
- [ ] **Runbooks** created for common operational tasks

#### **Application Integration**
- [ ] **Service registration** strategy defined
- [ ] **SPIFFE ID naming** convention established
- [ ] **TTL values** configured based on security requirements
- [ ] **Workload attestation** selectors defined
- [ ] **mTLS implementation** validated across services

### üìö **Template Customization Examples**

#### **Multi-Cluster Federation**

```yaml
# values/multi-cluster.yaml
spireServer:
  config:
    # Enable federation
    federation:
      enabled: true
      bundleEndpoint:
        address: "0.0.0.0"
        port: 8443
      
  # Federation service
  federationService:
    enabled: true
    type: LoadBalancer
    port: 8443

# Cross-cluster trust configuration
federatedTrustDomains:
  - trustDomain: "cluster-east.company.internal"
    bundleEndpointURL: "https://spire-east.company.internal:8443"
  - trustDomain: "cluster-west.company.internal"
    bundleEndpointURL: "https://spire-west.company.internal:8443"
```

#### **Custom Node Attestation**

```yaml
# values/custom-attestation.yaml
spireServer:
  config:
    plugins:
      nodeAttestors:
        k8s_psat:
          enabled: true
          config:
            clusters:
              production-cluster:
                service_account_allow_list:
                  - "spire:spire-agent"
        
        # Add custom attestation plugin
        custom_attestor:
          enabled: true
          plugin_cmd: "/opt/custom-attestor"
          plugin_data:
            config_path: "/etc/custom-attestor/config.yaml"
```

### üéØ **Getting Started with the Template**

#### **Quick Start for Production**

1. **Copy the template:**
```bash
git clone <this-repository>
cp -r helm-charts/spire /path/to/your/infrastructure/
```

2. **Customize for your organization:**
```bash
# Edit chart values for your environment
vi /path/to/your/infrastructure/spire/values/production.yaml

# Add your trust domain and cluster configuration
# Configure your image registry and versions
# Set up your storage classes and resource requirements
```

3. **Deploy to production:**
```bash
helm install spire-prod /path/to/your/infrastructure/spire \
  --namespace spire-production \
  --create-namespace \
  --values /path/to/your/infrastructure/spire/values/production.yaml
```

4. **Verify and integrate:**
```bash
# Verify deployment
helm status spire-prod -n spire-production

# Test SPIRE functionality
kubectl exec -n spire-production deployment/spire-prod-server -- \
  /opt/spire/bin/spire-server entry show
```

This Helm chart template provides a **production-ready foundation** for implementing SPIRE in enterprise Kubernetes environments, with comprehensive security, monitoring, and operational capabilities built-in.

For detailed implementation guidance, see:
- [Helm Deployment Guide](HELM_DEPLOYMENT_GUIDE.md) - Complete deployment procedures
- [SPIFFE Service Integration Guide](SPIFFE_SERVICE_INTEGRATION_GUIDE.md) - Service onboarding
- [Chart Documentation](helm-charts/spire/README.md) - Detailed chart reference
