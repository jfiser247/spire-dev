# SPIFFE/SPIRE Local Development Environment

**üöÄ Quick Setup ‚Üí üî¨ Local Testing ‚Üí üè¢ Enterprise Deployment**

Complete local SPIFFE/SPIRE development environment designed for macOS that provides a clean, reproducible setup for enterprise-grade identity management. The idempotent setup tears down any existing environment and rebuilds from scratch.

## üìã Prerequisites

**System Requirements:**
- macOS (designed and tested on macOS)
- Container runtime: Docker Desktop or Rancher Desktop installed and running
- 8GB+ RAM recommended for multi-cluster operation
- SSD storage recommended for optimal performance

**Required Tools:**
Install via Homebrew:
```bash
brew install minikube kubectl node jq
```

**Dependencies:**
- **minikube**: Creates local Kubernetes clusters
- **kubectl**: Kubernetes command-line tool
- **node**: Node.js runtime for dashboard server
- **jq**: JSON processor for API data handling
- **Container Runtime**: Docker Desktop or Rancher Desktop
  - **Docker Desktop**: Traditional Docker solution with GUI
  - **Rancher Desktop**: Open-source alternative with built-in Kubernetes support

**Optional but Recommended:**
- **Homebrew**: Package manager for macOS
- **curl**: HTTP client (usually pre-installed on macOS)

## üöÄ Quick Start

### **One-Command Setup**
```bash
# Complete local SPIRE development environment with dashboard
./scripts/fresh-install.sh
```

**‚ú® Dashboard Ready:** http://localhost:3000/web-dashboard.html

This script:
- üßπ Completely tears down any existing SPIRE environment
- üîÑ Cleans all local configurations (Docker, minikube, kubectl contexts)
- üöÄ Sets up fresh clusters from scratch 
- üìä Starts the dashboard with real-time data
- ‚úÖ Validates the installation with comprehensive checks

**Average Runtime:** ~1.5-2 minutes *(verified on macOS with Docker Desktop and Rancher Desktop)*

### **Alternative: Manual Setup**
```bash
# Step-by-step control
./scripts/setup-clusters.sh
./scripts/verify-setup.sh
./web/start-dashboard.sh
```

### **Reset Environment**
```bash
# Return to clean development environment anytime
./scripts/fresh-install.sh
```

## üèóÔ∏è Architecture

### Local Testing Environment
Two minikube clusters simulating enterprise multi-cluster topology:

1. **SPIRE Server Cluster** (`spire-server-cluster`): Identity control plane
   - SPIRE Server for SPIFFE ID management
   - PostgreSQL database for registration entries

2. **Workload Cluster** (`workload-cluster`): Application workload environment  
   - SPIRE Agent for workload attestation
   - Enterprise service examples (user-service, payment-api, inventory-service)
   - Real-time monitoring dashboard

### Enterprise Deployment Path
*In production environments*, this architecture scales to multiple geographic regions with dedicated SPIRE servers, separate clusters for different security zones, and high-availability PostgreSQL with backup/recovery.

## üíª Local Development Dashboard

Perfect for local development with live data from your minikube clusters:

```bash
# Setup automatically starts the dashboard
./scripts/fresh-install.sh

# Dashboard is ready at: http://localhost:3000/web-dashboard.html
open http://localhost:3000/web-dashboard.html
```

**Manual Dashboard Control** (if needed):
```bash
# Restart dashboard manually
./web/start-dashboard.sh

# Verify dashboard is running with real data
./scripts/verify-setup.sh
```

The dashboard provides **real-time pod data** from both clusters, ideal for:
- Testing identity propagation across services
- Debugging SPIRE agent connectivity issues  
- Monitoring certificate expiration during development
- Validating configuration changes instantly
- **Drilldown debugging**: Click any pod name for detailed inspection

## üéØ Enterprise Features

### Enhanced Dashboard
Industry-standard SPIFFE/SPIRE observability with:
- Five-tile overview with dynamic SPIRE metrics integration
- **Interactive drilldown**: Click any pod name to view detailed `kubectl describe` output
- Command integration with built-in kubectl and metrics collection
- Export ready for integration with monitoring platforms

### Production Workload Services
Three example enterprise services with realistic configurations:
- **User Management API** (user-service): User authentication and identity management
- **Payment Processing API** (payment-api): Financial transaction processing
- **Inventory Management Service** (inventory-service): Supply chain and stock management

## üìä PostgreSQL Storage Planning

<details>
<summary>Click to expand storage considerations</summary>

### Local Development Storage
- **Current Allocation**: 5GB (optimal for local development)
- **Minimum**: 2GB (basic testing)
- **Recommended**: 5GB (extensive testing scenarios)
- **Maximum**: 10GB (complex multi-workload development)

### Enterprise Production Storage

| Deployment Size | Registration Entries | Database Size | Recommended Storage | Buffer |
|-----------------|---------------------|---------------|-------------------|--------|
| **Small** (100-500 workloads) | 1K-5K entries | ~10-50MB | **20GB** | 400x |
| **Medium** (500-2K workloads) | 5K-20K entries | ~50-200MB | **100GB** | 500x |
| **Large** (2K-10K workloads) | 20K-100K entries | ~200MB-1GB | **500GB** | 500x |
| **Enterprise** (10K+ workloads) | 100K+ entries | ~1-5GB | **2TB+** | 400x |

### Storage Requirements Breakdown
- **Base PostgreSQL Installation**: ~200-500MB
- **SPIRE Registration Data**: ~10KB per entry average
- **PostgreSQL Overhead**: 20-30% of data size
- **High Availability**: Primary + 2-3 replicas + backup volumes

</details>

## üîç Interactive Dashboard Features

### Pod Drilldown Capability
The dashboard now includes **clickable pod names** that provide instant access to detailed pod information:

**How it works:**
1. Navigate to any tab: **SPIRE Server**, **Agents**, or **Workloads**
2. Click on any pod name (shown as blue underlined text)
3. View complete `kubectl describe` output in a modal popup
4. Inspect pod status, events, volumes, and configuration details

**Available for:**
- ‚úÖ **SPIRE Server pods** (`spire-server-cluster`)
- ‚úÖ **SPIRE Database pods** (`spire-server-cluster`) 
- ‚úÖ **SPIRE Agent pods** (`workload-cluster`)
- ‚úÖ **Workload Service pods** (`workload-cluster`)

**Security:** Only authorized namespaces and contexts are accessible through the drilldown feature.

## üîç Useful Commands

### SPIFFE Namespace Structure (Best Practices)
Following official SPIFFE documentation recommendations:

- **`spire-server`** - SPIRE Server, PostgreSQL database, control plane
- **`spire-system`** - SPIRE Agents and system components  
- **`production`** - Enterprise workload services

### Common Operations
```bash
# Check all components
kubectl --context spire-server-cluster -n spire-server get pods
kubectl --context workload-cluster -n spire-system get pods
kubectl --context workload-cluster -n production get pods

# View SPIRE registrations
kubectl --context spire-server-cluster -n spire-server exec spire-server-0 -- \
  /opt/spire/bin/spire-server entry show

# Check database storage
kubectl --context spire-server-cluster -n spire-server get pvc

# View logs
kubectl --context spire-server-cluster -n spire-server logs spire-server-0
kubectl --context workload-cluster -n spire-system logs -l app=spire-agent
```

## üõ†Ô∏è Troubleshooting

**Having issues?** The setup script solves 90% of problems:
```bash
./scripts/fresh-install.sh  # ‚Üê Try this first!
```

**Common Issues:**
- **Dashboard shows mock data**: Wait 30-60 seconds for pods to fully start
- **Pods not starting**: Check Pod Security Standards with `kubectl describe pod`
- **Minikube issues**: Delete all profiles and restart: `minikube delete --all`

### ‚ö†Ô∏è Known Issue: SPIRE Agent Network Connectivity

**Issue**: SPIRE Agent may experience `CrashLoopBackOff` due to network timeouts between Minikube clusters.

**Symptoms**:
```
error="create attestation client: failed to dial dns:///192.168.49.2:31583: context deadline exceeded"
```

**Current Status**: 
- ‚úÖ **SPIRE Server & Database**: Work perfectly (100% success rate)
- ‚úÖ **Workload Services**: Deploy successfully (7/7 pods running)
- ‚ùå **Cross-cluster Agent**: Network connectivity issues in multi-cluster Minikube setup

**Workarounds**:
1. **Single-cluster deployment**: Deploy server and agent in same cluster
2. **Alternative runtimes**: Test with Kind or real Kubernetes clusters
3. **Network debugging**: Check Minikube network configuration

**This is a known limitation of the multi-cluster Minikube networking setup and does not affect production deployments.**

For detailed troubleshooting: **[docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)**

## üè¢ Enterprise Deployment

### Adapting for Production Kubernetes
While this project excels at local development, **enterprise deployment** requires:

**Security Hardening:**
- Replace minikube with production Kubernetes clusters (EKS, GKE, AKS)
- Implement proper RBAC with service accounts and role bindings
- Use secrets management (Vault, AWS Secrets Manager)
- Enable TLS encryption for all SPIRE server communications

**High Availability:**
- Deploy SPIRE server with multiple replicas and load balancing
- Configure PostgreSQL with primary/replica setup and automated failover
- Implement cross-region trust bundle distribution
- Set up cluster auto-scaling and resource limits

**Operations & Monitoring:**
- Integrate with enterprise logging (Splunk, ELK stack)
- Set up Prometheus metrics collection and Grafana dashboards
- Configure alerting for SPIRE server downtime and certificate expiration
- Implement backup/restore procedures for registration entries

**See [docs/HELM_DEPLOYMENT_GUIDE.md](docs/HELM_DEPLOYMENT_GUIDE.md) for production deployment using Helm charts.**

## üìÅ Project Structure

```
spire-dev/
‚îú‚îÄ‚îÄ k8s/                          # Kubernetes manifests
‚îÇ   ‚îú‚îÄ‚îÄ spire-server/             # SPIRE server and database
‚îÇ   ‚îî‚îÄ‚îÄ workload-cluster/         # Agents and workload services
‚îú‚îÄ‚îÄ scripts/                      # Setup and utility scripts
‚îÇ   ‚îú‚îÄ‚îÄ fresh-install.sh          # Main fresh install script
‚îÇ   ‚îú‚îÄ‚îÄ setup-clusters.sh         # Manual cluster setup
‚îÇ   ‚îî‚îÄ‚îÄ verify-setup.sh           # Verification and testing
‚îú‚îÄ‚îÄ web/                          # Web dashboard
‚îÇ   ‚îú‚îÄ‚îÄ web-dashboard.html        # Main dashboard interface
‚îÇ   ‚îú‚îÄ‚îÄ server.js                 # Node.js server
‚îÇ   ‚îî‚îÄ‚îÄ start-dashboard.sh        # Startup script
‚îú‚îÄ‚îÄ docs/                         # Documentation
‚îî‚îÄ‚îÄ helm-charts/                  # Helm deployment configurations
```

## üéâ Next Steps

1. **Start with the setup**: `./scripts/fresh-install.sh`
2. **Open the dashboard**: http://localhost:3000/web-dashboard.html
3. **Explore the clusters**: Use the commands above to inspect your setup
4. **Experiment with services**: Modify the workload deployments in `k8s/workload-cluster/`
5. **Scale to production**: Follow the enterprise deployment guide

For complete documentation see: **[docs/PROJECT_STRUCTURE.md](docs/PROJECT_STRUCTURE.md)**

---

**Local Development ‚Üí Production Ready in 2 minutes** ‚ö°